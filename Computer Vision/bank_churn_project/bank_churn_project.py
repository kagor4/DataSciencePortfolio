# -*- coding: utf-8 -*-
"""review_homework_id_1032049.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F51KubwBRFHzbOpahQzWEbDtFSbDjpwP

# Отток клиентов

Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.

Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.

Постройте модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте *F1*-меру на тестовой выборке самостоятельно.

Дополнительно измеряйте *AUC-ROC*, сравнивайте её значение с *F1*-мерой.

Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)

Целью данного проекта является построение модели для прогнозирования ухода клиентов из "Бета-Банка". В качестве ключевой метрики качества модели установлено значение F1-меры, которое необходимо повысить до минимума 0.59.

Порядок действий:

1. Загрузка и подготовка данных: В начале проекта мы загрузим и проведем предварительную обработку данных. Это включает в себя изучение данных, обработку пропущенных значений и выбор признаков, которые будут использоваться для построения модели.

2. Исследование баланса классов: Мы проведем анализ баланса классов, чтобы определить, насколько дисбалансирована выборка. Затем обучим модель без учета дисбаланса и сравним результаты.

3. Улучшение качества модели с учетом дисбаланса классов: Мы будем использовать различные методы для борьбы с дисбалансом классов, такие как взвешивание классов, андерсэмплинг и оверсэмплинг. Обучим несколько различных моделей и найдем лучшую, учитывая дисбаланс классов.

4. Финальное тестирование: На этом этапе мы проведем финальное тестирование выбранной модели на тестовой выборке. Мы также измерим AUC-ROC и сравним его значение с F1-мерой.

Целью проекта является построение надежной модели для прогнозирования ухода клиентов, что позволит "Бета-Банку" удерживать своих клиентов и повышать качество обслуживания.

## Подготовка данных
"""

import pandas as pd
import os
import numpy as np
import matplotlib.pyplot as plt
import sklearn
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import train_test_split
from sklearn.dummy import DummyClassifier
from sklearn.preprocessing import OrdinalEncoder, StandardScaler
from sklearn.metrics import recall_score, precision_score, f1_score, make_scorer, roc_auc_score, accuracy_score
from sklearn.metrics import confusion_matrix, roc_curve, auc, ConfusionMatrixDisplay
from sklearn.utils import shuffle
from tqdm import tqdm

"""Функция для равномерного заполнения пропусков в столбцах:"""

def fill_nan_uniformly(df, column):
    non_nan_values = df[column].dropna()
    nan_count = df[column].isnull().sum()
    replacement_values = np.random.choice(non_nan_values, size = nan_count)
    df.loc[df[column].isnull(), column] = replacement_values

"""Создам функцию для подсчета метрик моделей и красивой визаулизации результата:"""

def evaluate_model(model, features, target):
    predictions = model.predict(features)

    accuracy = accuracy_score(target, predictions)
    precision = precision_score(target, predictions)
    recall = recall_score(target, predictions)
    f1 = f1_score(target, predictions)

    cm = confusion_matrix(target, predictions)

    fpr, tpr, thresholds = roc_curve(target, model.predict_proba(features)[:, 1])
    roc_auc = auc(fpr, tpr)

    print(f"Accuracy: {accuracy:.2f}")
    print(f"Precision: {precision:.2f}")
    print(f"Recall: {recall:.2f}")
    print(f"F1 Score: {f1:.2f}")
    print(f"ROC AUC: {roc_auc:.2f}")

    print("Confusion Matrix:")
    print(cm)

    cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)
    cm_display.plot(cmap='viridis', values_format='d')

    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve')
    plt.legend(loc='lower right')
    plt.show()

    return {
        "Accuracy": accuracy,
        "Precision": precision,
        "Recall": recall,
        "F1 Score": f1,
        "ROC AUC": roc_auc,
        "Confusion Matrix": cm
    }

"""Создам функцию для upsample:"""

def upsample(features, target, repeat):
    features_zeros = features[target == 0]
    features_ones = features[target == 1]
    target_zeros = target[target == 0]
    target_ones = target[target == 1]

    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)
    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)

    features_upsampled, target_upsampled = shuffle(
        features_upsampled, target_upsampled, random_state=12345)

    return features_upsampled, target_upsampled

"""Cоздам функцию, определяющую оптимальное значения repeat:"""

def find_optimal_repeat_for_balance(features_train, target_train, repeat_range):
    best_balance = float('inf')
    best_repeat = 0

    for repeat in repeat_range:
        features_upsampled_train, target_upsampled_train = upsample(features_train, target_train, repeat)


        count_class_0 = target_upsampled_train.value_counts()[0]
        count_class_1 = target_upsampled_train.value_counts()[1]
        balance = abs(count_class_0 - count_class_1)

        if balance < best_balance:
            best_balance = balance
            best_repeat = repeat

    return best_repeat, best_balance

"""Создам функцию для downsample:"""

def downsample(features, target, fraction):
    features_zeros = features[target == 0]
    features_ones = features[target == 1]
    target_zeros = target[target == 0]
    target_ones = target[target == 1]

    features_downsampled = pd.concat(
        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])
    target_downsampled = pd.concat(
        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])

    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=12345)

    return features_downsampled, target_downsampled

"""Cоздам функцию, определяющую оптимальное значения fraction:"""

def find_optimal_fraction_for_balance(features_train, target_train, fraction_range):
    best_balance = float('inf')
    best_fraction = 0

    for fraction in fraction_range:
        features_downsample_train, target_downsample_train = downsample(features_train, target_train, fraction)


        count_class_0 = target_downsample_train.value_counts()[0]
        count_class_1 = target_downsample_train.value_counts()[1]
        balance = abs(count_class_0 - count_class_1)

        if balance < best_balance:
            best_balance = balance
            best_fraction = fraction

    return best_fraction, best_balance

data = '/datasets/Churn.csv'

if os.path.exists(data):
    df = pd.read_csv(data)
else:
    print('Something is wrong')

df.head()

df = df.drop(['Surname', 'RowNumber'], axis=1)

"""Удалим столбцы RowNumber и Surname, так как столбцы индексов и фамилий клиентов не являются важными, на чем модель может обучаться."""

df.head()

df.info()

# df = df.dropna(subset=['Tenure'])

"""Для заполнения пропусков в столбце Tenure, изучим этот столбец на зависимось от других столбцов."""

pd.pivot_table(df, values=['Balance', 'Age', 'CreditScore', 'NumOfProducts', ], index='Tenure')

"""Распределение по столбцу Tenure является равномерным. По этому пропуски в этом столбце заполним равномерно, так чтобы это распределение не изменилось."""

fill_nan_uniformly(df, 'Tenure')

df.info()

df['Tenure'].unique()

df.describe()

df.columns = ['customer_id', 'credit_score', 'geography', 'gender', 'age', 'tenure', 'balance',
              'num_of_products', 'has_cr_card', 'is_active_member', 'estimated_salary', 'exited']

df.head()

class_counts = df['exited'].value_counts()

plt.figure(figsize=(6, 4))
class_counts.plot(kind='bar', color=['skyblue', 'lightcoral'])
plt.title('Распределение классов в "exited"')
plt.xlabel('Класс')
plt.ylabel('Количество')
plt.xticks([0, 1], ['Оставшиеся', 'Ушедшие'])
plt.show()

df = pd.get_dummies(df, columns=['geography'], prefix=['geography'], drop_first=True)
df = pd.get_dummies(df, columns=['gender'], prefix=['gender'], drop_first=True)
df.columns = df.columns.str.lower()

target = df['exited']
features = df.drop(['exited'], axis=1)

features_train, features_temp, target_train, target_temp = train_test_split(
    features, target, test_size=0.4, random_state=12345)
features_valid, features_test, target_valid, target_test = train_test_split(
    features_temp, target_temp, test_size=0.5, random_state=12345)

numeric = ['customer_id', 'credit_score', 'age', 'tenure', 'balance', 'num_of_products',
           'has_cr_card', 'is_active_member', 'estimated_salary',
           'geography_germany', 'geography_spain', 'gender_male']

df.info()

scaler = StandardScaler()
scaler.fit(features_train[numeric])

pd.options.mode.chained_assignment = None

features_train[numeric] = scaler.transform(features_train[numeric])
features_valid[numeric] = scaler.transform(features_valid[numeric])
features_test[numeric] = scaler.transform(features_test[numeric])

"""## Исследование задачи"""

geography_counts = df[['geography_germany', 'geography_spain']].value_counts()
gender_counts = df['gender_male'].value_counts()

print('Распределение стран по категориям;')
print(geography_counts)
plt.figure(figsize=(8, 6))
geography_counts.plot(kind='bar', color='skyblue', edgecolor='black')
plt.xlabel('Категории стран')
plt.ylabel('Количество')
plt.title('Распределение стран по категориям')
for i, count in enumerate(geography_counts):
    plt.text(i, count, str(count), ha='center', va='bottom')
plt.show()

print('Распределение полов по категориям:')
print(gender_counts)
gender_counts.plot(kind='bar', color='skyblue', edgecolor='black')
plt.xlabel('Категории полов')
plt.ylabel('Количество')
plt.title('Распределение полов по категориям')
for i, count in enumerate(gender_counts):
    plt.text(i, count, str(count), ha='center', va='bottom')
plt.show()

"""На основе этой информации, мы можем сделать вывод о балансе классов внутри категориальных признаков 'geography' и 'gender'. В данном случае, 'geography' имеет разнообразие категорий, и категория '0' встречается чаще всего, а распределение '1' и '2' не слишком неравномерно. Распределение 'gender' показывает некоторый дисбаланс.

Проведём исследование дерева решений
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# max_depth_values = []
# f1_values = []
# trees = []
# 
# for depth in range(1, 16, 1):
#     model = DecisionTreeClassifier(random_state=12345, max_depth=depth)
#     model.fit(features_train, target_train)
#     predictions_valid = model.predict(features_valid)
#     f1 = f1_score(target_valid, predictions_valid)
#     max_depth_values.append(depth)
#     f1_values.append(f1)
#     trees.append(model)
#     print('max_depth =', depth, ':',  f1)
# 
# plt.figure(figsize=(8, 6))
# plt.plot(max_depth_values,  f1_values, marker='o', linestyle='-')
# plt.title('Зависимость F1-метрики от max_depth')
# plt.xlabel('max_depth')
# plt.ylabel('F1-метрика')
# plt.grid(True)
# plt.show()

"""Максимальное значение F1-меры модели DecisionTreeClassifier достигается при max_depth = 6, что указывает на оптимальную глубину для достижения баланса между точностью и полнотой модели."""

selected_depth = 3

plt.figure(figsize=(16, 12))
plot_tree(trees[selected_depth - 1], filled=True, feature_names=features_train.columns, class_names=["0", "1"])
plt.title(f'Decision Tree (max_depth={selected_depth})')
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# min_samples_leaf_values = []
# f1_values = []
# 
# for min_samples_leaf in range(1, 20, 1):
#     model = DecisionTreeClassifier(random_state=12345, min_samples_leaf=min_samples_leaf)
#     model.fit(features_train, target_train)
#     predictions_valid = model.predict(features_valid)
#     f1 = f1_score(target_valid, predictions_valid)
#     min_samples_leaf_values.append(min_samples_leaf)
#     f1_values.append(f1)
#     print('min_samples_leaf =', min_samples_leaf, ':', f1)
# 
# plt.figure(figsize=(8, 6))
# plt.plot(min_samples_leaf_values, f1_values, marker='o', linestyle='-')
# plt.title('Зависимость F1-метрики от min_samples_leaf')
# plt.xlabel('min_samples_leaf')
# plt.ylabel('F1-метрика')
# plt.grid(True)
# plt.show()

"""Максимальное значение F1-меры достигается при min_samples_leaf = 14, что указывает на оптимальное количество минимальных образцов в листьях дерева для достижения лучшего сочетания точности и полноты модели DecisionTreeClassifier."""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# criterion_values = ['gini', 'entropy']
# f1_values = []
# 
# for criterion in criterion_values:
#     model = DecisionTreeClassifier(random_state=12345, criterion=criterion)
#     model.fit(features_train, target_train)
#     predictions_valid = model.predict(features_valid)
#     f1 = f1_score(target_valid, predictions_valid)
#     f1_values.append(f1)
#     print('criterion =', criterion, ':', f1)
# 
# plt.figure(figsize=(8, 6))
# plt.bar(criterion_values, f1_values)
# plt.title('Зависимость F1-метрики от criterion')
# plt.xlabel('criterion')
# plt.ylabel('F1-метрика')
# plt.grid(True)
# plt.show()

"""Использование критерия "entropy" приводит к более высокому значению F1-меры (0.49), чем критерий "gini" (0.46), что указывает на лучшую способность модели DecisionTreeClassifier разделять классы с использованием энтропийного критерия.

Сравнив результаты трех различных аспектов модели DecisionTreeClassifier, можно сделать следующие выводы:

1. Максимальное значение F1-меры достигается при max_depth = 6, что указывает на оптимальную глубину для достижения баланса между точностью и полнотой модели DecisionTreeClassifier.

2. Максимальное значение F1-меры достигается при min_samples_leaf = 14, что указывает на оптимальное количество минимальных образцов в листьях дерева для достижения лучшего сочетания точности и полноты модели DecisionTreeClassifier.

3. Использование критерия "entropy" приводит к более высокому значению F1-меры (0.51), чем критерий "gini" (0.49), что указывает на лучшую способность модели DecisionTreeClassifier разделять классы с использованием энтропийного критерия.

Таким образом, для модели DecisionTreeClassifier, оптимальные параметры max_depth, min_samples_leaf и критерий деления могут значительно повысить значение F1-меры, что важно для задачи бинарной классификации.

Построим итоговую модель дерева решений с наилучшими получившимися геперпараметрами и узнаем её F1-метрику.
"""

model = DecisionTreeClassifier(random_state=12345, max_depth=6, criterion='entropy', min_samples_leaf=14)
model.fit(features_train, target_train)
predictions_valid = model.predict(features_valid)
f1 = f1_score(target_valid, predictions_valid)
print('F1-метрика составляет:', f1)

"""Проведу подбор сразу нескольких гиперпараметров."""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# max_depth_range = range(1, 17)
# criterion_options = ['gini', 'entropy']
# min_samples_leaf_options = range(1, 21)
# 
# best_f1 = 0
# best_params = {}
# 
# for max_depth_value in tqdm(max_depth_range, desc="max_depth"):
#     for criterion_value in criterion_options:
#         for min_samples_leaf_value in min_samples_leaf_options:
#             model = DecisionTreeClassifier(
#                 random_state=12345,
#                 max_depth=max_depth_value,
#                 criterion=criterion_value,
#                 min_samples_leaf=min_samples_leaf_value
#             )
# 
#             model.fit(features_train, target_train)
# 
#             predictions_valid = model.predict(features_valid)
# 
#             f1 = f1_score(target_valid, predictions_valid)
# 
#             if f1 > best_f1:
#                 best_f1 = f1
#                 best_params = {
#                     'max_depth': max_depth_value,
#                     'criterion': criterion_value,
#                     'min_samples_leaf': min_samples_leaf_value
#                 }
# 
# print("Лучшие параметры:", best_params)
# print("Лучшая F1-метрика:", best_f1)

model = DecisionTreeClassifier(random_state=12345, max_depth=9, criterion='gini', min_samples_leaf=2)
model.fit(features_train, target_train)
metrics = evaluate_model(model, features_valid, target_valid)
print(metrics)

"""Наилучшие параметры для модели DecisionTreeClassifier:

- Глубина дерева: 9
- Критерий разделения: Gini
- Минимальное количество выборок в листьях: 2


Результаты на валидационной выборке:

- Accuracy: 0.86
- Precision: 0.73
- Recall): 0.49
- F1 Score: 0.58
- ROC AUC: 0.81

Модель показывает хорошую точность и точность предсказаний, но есть некоторый баланс между полнотой и точностью, который может быть настроен в зависимости от задачи.

<div class="alert alert-info">
<h2> Комментарий студента: <a class="tocSkip"> </h2>

Сделал подбор через циклы, модель и правда стала лучше. Так же сделал функцию с перечислением разных метрик.
</div>

<br/>

Проведем исследование случайного леса.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# n_estimators_values = []
# f1_values = []
# 
# for n_estimators in range(10, 301, 10):
#     model = RandomForestClassifier(random_state=12345, n_estimators=n_estimators)
#     model.fit(features_train, target_train)
#     predictions_valid = model.predict(features_valid)
#     f1 = f1_score(target_valid, predictions_valid)
#     n_estimators_values.append(n_estimators)
#     f1_values.append(f1)
#     print('n_estimators =', n_estimators, ':', f1)
# 
# plt.figure(figsize=(10, 6))
# plt.plot(n_estimators_values, f1_values, marker='o', linestyle='-')
# plt.title('Зависимость F1-метрики от n_estimators')
# plt.xlabel('n_estimators')
# plt.ylabel('F1-метрика')
# plt.grid(True)
# plt.show()

"""Максимальное значение F1-меры для модели RandomForestClassifier достигается при n_estimators = 50, что указывает на оптимальное количество деревьев в ансамбле для достижения лучшего баланса между точностью и полнотой модели."""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# max_depth_values = []
# f1_values = []
# 
# for max_depth in range(1, 42, 2):
#     model = RandomForestClassifier(random_state=12345, max_depth=max_depth, n_estimators=71)  # Здесь n_estimators=71, выберите оптимальное значение
#     model.fit(features_train, target_train)
#     predictions_valid = model.predict(features_valid)
#     f1 = f1_score(target_valid, predictions_valid)
#     max_depth_values.append(max_depth)
#     f1_values.append(f1)
#     print('max_depth =', max_depth, ':', f1)
# 
# plt.figure(figsize=(10, 6))
# plt.plot(max_depth_values, f1_values, marker='o', linestyle='-')
# plt.title('Зависимость F1-метрики от max_depth')
# plt.xlabel('max_depth')
# plt.ylabel('F1-метрика')
# plt.grid(True)
# plt.show()

"""Максимальное значение F1-меры для модели RandomForestClassifier достигается при max_depth = 31, что указывает на оптимальную глубину дерева для достижения лучшего баланса между точностью и полнотой модели. Дальнейшее увеличение глубины дерева не приводит к значительному увеличению F1-меры."""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# min_samples_leaf_values = []
# f1_values = []
# 
# for min_samples_leaf in range(1, 11):
#     model = RandomForestClassifier(random_state=12345, min_samples_leaf=min_samples_leaf, n_estimators=71, max_depth=10)
#     model.fit(features_train, target_train)
#     predictions_valid = model.predict(features_valid)
#     f1 = f1_score(target_valid, predictions_valid)
#     min_samples_leaf_values.append(min_samples_leaf)
#     f1_values.append(f1)
#     print('min_samples_leaf =', min_samples_leaf, ':', f1)
# 
# plt.figure(figsize=(10, 6))
# plt.plot(min_samples_leaf_values, f1_values, marker='o', linestyle='-')
# plt.title('Зависимость F1-метрики от min_samples_leaf')
# plt.xlabel('min_samples_leaf')
# plt.ylabel('F1-метрика')
# plt.grid(True)
# plt.show()

"""Максимальное значение F1-меры для модели RandomForestClassifier достигается при min_samples_leaf = 2, что указывает на оптимальное количество минимальных объектов в листьях деревьев для достижения лучшего баланса между точностью и полнотой модели. Дальнейшее увеличение значения min_samples_leaf не приводит к значительному увеличению F1-меры.

В результате исследования трех аспектов модели RandomForestClassifier можно сделать следующие выводы:

1. Максимальное значение F1-меры достигается при n_estimators = 50, что указывает на оптимальное количество деревьев в ансамбле для достижения наилучшего баланса между точностью и полнотой модели.

2. Максимальное значение F1-меры достигается при max_depth = 31, указывая на оптимальную глубину дерева для наилучшего сочетания точности и полноты модели. Повышение глубины дерева не приводит к значительному увеличению F1-меры.

3. Максимальное значение F1-меры достигается при min_samples_leaf = 2, указывая на оптимальное количество минимальных объектов в листьях деревьев для наилучшего баланса между точностью и полнотой модели. Дальнейшее увеличение значения min_samples_leaf не приводит к существенному повышению F1-меры.

Таким образом, настройка параметров модели RandomForestClassifier позволяет достичь оптимального баланса в прогнозах между точностью и полнотой, что важно для задач бинарной классификации.

Построим итоговую модель случайного леса с наилучшими получившимися геперпараметрами и узнаем её F1-метрику.
"""

model = RandomForestClassifier(random_state=12345, n_estimators=50, max_depth=31, min_samples_leaf=2)
model.fit(features_train, target_train)
predictions_valid = model.predict(features_valid)
f1 = f1_score(target_valid, predictions_valid)
print('F1-метрика составляет:', f1)

"""Проведу подбор сразу нескольких гиперпараметров."""

max_depth_range = range(1, 17)
n_estimators_range = list(range(10, 301, 10))
min_samples_leaf_range = range(1, 21)

best_f1 = 0
best_params = {}

for max_depth_value in max_depth_range:
    for n_estimators_value in tqdm(n_estimators_range, desc=f"max_depth={max_depth_value}"):
        for min_samples_leaf_value in min_samples_leaf_range:
            model = RandomForestClassifier(
                random_state=12345,
                max_depth=max_depth_value,
                n_estimators=n_estimators_value,
                min_samples_leaf=min_samples_leaf_value
            )

            model.fit(features_train, target_train)

            predictions_valid = model.predict(features_valid)

            f1 = f1_score(target_valid, predictions_valid)

            if f1 > best_f1:
                best_f1 = f1
                best_params = {
                    'max_depth': max_depth_value,
                    'n_estimators': n_estimators_value,
                    'min_samples_leaf': min_samples_leaf_value
                }

print("Лучшие параметры:", best_params)
print("Лучшая F1-метрика:", best_f1)

"""Лучшие параметры: {'max_depth': 16, 'n_estimators': 10, 'min_samples_leaf': 2}

Лучшая F1-метрика: 0.587719298245614
"""

model = RandomForestClassifier(random_state=12345, n_estimators=10, max_depth=16, min_samples_leaf=2)
model.fit(features_train, target_train)
metrics = evaluate_model(model, features_valid, target_valid)
print(metrics)

"""Лучшие параметры для модели RandomForestClassifier:

- Глубина дерева: 16
- Количество деревьев (n_estimators): 10
- Минимальное количество выборок в листьях: 2

Результаты на валидационной выборке:

- Accuracy: 0.859
- Precision: 0.756
- Recall: 0.481
- F1 Score: 0.588
- ROC AUC: 0.810

Модель RandomForestClassifier также демонстрирует хорошие показатели, сравнимые с моделью DecisionTreeClassifier, и обеспечивает хороший баланс между точностью и полнотой в зависимости от задачи классификации.

Проведем исследование логистической регрессии.
"""

C_values = []
f1_values = []

for C in [0.001, 0.01, 0.1, 1, 10, 100]:
    model = LogisticRegression(random_state=12345, C=C)
    model.fit(features_train, target_train)
    predictions_valid = model.predict(features_valid)
    f1 = f1_score(target_valid, predictions_valid)
    C_values.append(C)
    f1_values.append(f1)
    print('C =', C, ':', f1)

plt.figure(figsize=(10, 6))
plt.semilogx(C_values, f1_values, marker='o', linestyle='-')
plt.title('Зависимость F1-метрики от C')
plt.xlabel('C')
plt.ylabel('F1-метрика')
plt.grid(True)
plt.show()

"""При использовании модели LogisticRegression, значение параметра регуляризации C оказывает огромное влияние на F1-меру. Наилучшее значение F1-меры достигается при C = 1."""

penalty_values = ['l1', 'l2']
f1_values = []

for penalty in penalty_values:
    model = LogisticRegression(random_state=12345, penalty='l1', solver='liblinear', C=1.0)
    model.fit(features_train, target_train)
    predictions_valid = model.predict(features_valid)
    f1 = f1_score(target_valid, predictions_valid)
    f1_values.append(f1)
    print('penalty =', penalty, ':', f1)

plt.figure(figsize=(6, 4))
plt.bar(penalty_values, f1_values)
plt.title('Зависимость F1-метрики от penalty')
plt.xlabel('penalty')
plt.ylabel('F1-метрика')
plt.grid(axis='y')
plt.show()

"""В данном случае, выбор типа penalty не оказывает существенного влияния на F1-меру при использовании модели LogisticRegression. Независимо от выбранного типа penalty, F1-мера остается на одном и том же уровне, равном приближенно 0.2283."""

solver_values = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']
f1_values = []

for solver in solver_values:
    model = LogisticRegression(random_state=12345, penalty='l2', solver=solver, C=1.0)
    model.fit(features_train, target_train)
    predictions_valid = model.predict(features_valid)
    f1 = f1_score(target_valid, predictions_valid)
    f1_values.append(f1)
    print('solver =', solver, ':', f1)

plt.figure(figsize=(10, 6))
plt.bar(solver_values, f1_values)
plt.title('Зависимость F1-метрики от solver')
plt.xlabel('solver')
plt.ylabel('F1-метрика')
plt.grid(axis='y')
plt.show()

"""В данном случае, выбор различных алгоритмов solver также не влияет на F1-меру при использовании модели LogisticRegression. Независимо от выбранного алгоритма, F1-мера остается на одном и том же уровне, равном приближенно 0.2283.

Исходя из результатов исследования модели LogisticRegression, можно сделать следующие выводы:

1. Параметр регуляризации C оказывает существенное влияние на F1-меру. Наилучшее значение F1-меры достигается при C = 1, что подчеркивает важность баланса между регуляризацией и точностью модели.

2. Выбор типа penalty (l1 или l2) не влияет существенно на F1-меру при использовании модели LogisticRegression. Независимо от выбранного типа penalty, F1-мера остается на почти одинаковом уровне, близком к 0.2283. Это может свидетельствовать о том, что в данном случае, тип регуляризации не является ключевым фактором в достижении баланса между точностью и полнотой.

3. Выбор различных алгоритмов solver также не влияет на F1-меру при использовании модели LogisticRegression. Независимо от выбранного алгоритма, F1-мера остается на почти одинаковом уровне, близком к 0.2283. Это указывает на отсутствие значительного влияния выбора алгоритма оптимизации на эффективность модели в данной задаче.

Таким образом, при настройке модели LogisticRegression, основное внимание следует уделить выбору параметра регуляризации C для достижения оптимального баланса между точностью и полнотой.

Построим итоговую модель логистической регрессии с наилучшими получившимися геперпараметрами и узнаем её F1-метрику.
"""

model = LogisticRegression(random_state=12345, C=1.0)
model.fit(features_train, target_train)
predictions_valid = model.predict(features_valid)
f1 = f1_score(target_valid, predictions_valid)
print('F1-метрика составляет:', f1)

penalty_options = ['l2']
solver_options = ['newton-cg', 'lbfgs', 'sag', 'saga']
C_values = [0.001, 0.01, 0.1, 1, 10, 100]

best_f1 = 0
best_params = {}

for penalty_value in penalty_options:
    for solver_value in solver_options:
        for C_value in C_values:
            model = LogisticRegression(
                random_state=12345,
                penalty=penalty_value,
                solver=solver_value,
                C=C_value
            )

            model.fit(features_train, target_train)

            predictions_valid = model.predict(features_valid)

            f1 = f1_score(target_valid, predictions_valid)

            if f1 > best_f1:
                best_f1 = f1
                best_params = {
                    'penalty': penalty_value,
                    'solver': solver_value,
                    'C': C_value
                }

print("Лучшие параметры:", best_params)
print("Лучшая F1-метрика:", best_f1)

model = LogisticRegression(random_state=12345, penalty='l2', solver='newton-cg', C=1.0)
model.fit(features_train, target_train)
metrics = evaluate_model(model, features_valid, target_valid)
print(metrics)

"""Наилучшие параметры для модели LogisticRegression:

- Тип штрафа (penalty): L2
- Метод оптимизации (solver): Newton-CG
- Параметр регуляризации (C): 1

Результаты на валидационной выборке:

- Accuracy: 0.80
- Precision: 0.57
- Recall: 0.19
- F1 Score: 0.28
- ROC AUC: 0.77

Модель LogisticRegression демонстрирует более низкие показатели по сравнению с предыдущими моделями. При этом точность и полнота сильно различаются, что может быть важным аспектом в задачах, где баланс между ними имеет решающее значение.

DecisionTreeClassifier и RandomForestClassifier обеспечивают хороший баланс между этими метриками, в то время как LogisticRegression имеет более низкую полноту при более низкой точности.

Исследованы три модели классификации с учетом дисбаланса классов: DecisionTreeClassifier, RandomForestClassifier и LogisticRegression.

DecisionTreeClassifier показал хорошие показатели точности и точности предсказаний, при этом обнаруживается компромисс между полнотой и точностью в зависимости от задачи. Оптимальные параметры для этой модели: максимальная глубина дерева - 9, критерий разделения - Gini, минимальное количество выборок в листьях - 2. На валидационной выборке получены следующие результаты: Accuracy - 0.86, Precision - 0.73, Recall - 0.49, F1 Score - 0.58, ROC AUC - 0.81.

RandomForestClassifier также продемонстрировал хорошие показатели сравнимые с DecisionTreeClassifier. Оптимальные параметры для этой модели: максимальная глубина дерева - 16, количество деревьев (n_estimators) - 10, минимальное количество выборок в листьях - 2. На валидационной выборке получены следующие результаты: Accuracy - 0.859, Precision - 0.756, Recall - 0.481, F1 Score - 0.588, ROC AUC - 0.810.

LogisticRegression показал более низкие показатели по сравнению с двумя другими моделями. Оптимальные параметры для этой модели: тип штрафа - L2, метод оптимизации - Newton-CG, параметр регуляризации - 1. На валидационной выборке получены следующие результаты: Accuracy - 0.80, Precision - 0.57, Recall - 0.19, F1 Score - 0.28, ROC AUC - 0.77.

Сравнительный анализ показывает, что DecisionTreeClassifier и RandomForestClassifier обеспечивают хороший баланс между точностью и полнотой в зависимости от задачи классификации, в то время как LogisticRegression имеет более низкую полноту при более низкой точности.

## Борьба с дисбалансом

Используем первый метод борьбы с дисбалансом - взвешивание классов.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# max_depth_range = range(1, 17)
# criterion_options = ['gini', 'entropy']
# min_samples_leaf_options = range(1, 21)
# 
# best_f1 = 0
# best_params = {}
# 
# for max_depth_value in tqdm(max_depth_range, desc="max_depth"):
#     for criterion_value in criterion_options:
#         for min_samples_leaf_value in min_samples_leaf_options:
#             model = DecisionTreeClassifier(
#                 random_state=12345,
#                 max_depth=max_depth_value,
#                 criterion=criterion_value,
#                 min_samples_leaf=min_samples_leaf_value,
#                 class_weight='balanced'
#             )
# 
#             model.fit(features_train, target_train)
# 
#             predictions_valid = model.predict(features_valid)
# 
#             f1 = f1_score(target_valid, predictions_valid)
# 
#             if f1 > best_f1:
#                 best_f1 = f1
#                 best_params = {
#                     'max_depth': max_depth_value,
#                     'criterion': criterion_value,
#                     'min_samples_leaf': min_samples_leaf_value
#                 }
# 
# print("Лучшие параметры:", best_params)
# print("Лучшая F1-метрика:", best_f1)

model = DecisionTreeClassifier(random_state=12345, max_depth=5, criterion='entropy', min_samples_leaf=9, class_weight='balanced')
model.fit(features_train, target_train)
metrics = evaluate_model(model, features_valid, target_valid)
print(metrics)

"""После использования взвешивания классов для модели DecisionTreeClassifier, получены следующие результаты на валидационной выборке:

- Accuracy: 0.81
- Precision: 0.55
- Recall: 0.68
- F1 Score: 0.60
- ROC AUC: 0.84

Матрица ошибок выглядит следующим образом:

[1346, 236]

[ 135, 283]


В результате использования взвешивания классов модель показала улучшение в показателях Recall, что означает, что она стала лучше обнаруживать положительные объекты. Однако Precision снизилась, что может быть компромиссом для увеличения полноты.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# max_depth_range = range(1, 17)
# n_estimators_range = list(range(10, 301, 10))
# min_samples_leaf_range = range(1, 21)
# 
# best_f1 = 0
# best_params = {}
# 
# for max_depth_value in max_depth_range:
#     for n_estimators_value in tqdm(n_estimators_range, desc=f"max_depth={max_depth_value}"):
#         for min_samples_leaf_value in min_samples_leaf_range:
#             model = RandomForestClassifier(
#                 random_state=12345,
#                 max_depth=max_depth_value,
#                 n_estimators=n_estimators_value,
#                 min_samples_leaf=min_samples_leaf_value,
#                 class_weight='balanced'
#             )
# 
#             model.fit(features_train, target_train)
# 
#             predictions_valid = model.predict(features_valid)
# 
#             f1 = f1_score(target_valid, predictions_valid)
# 
#             if f1 > best_f1:
#                 best_f1 = f1
#                 best_params = {
#                     'max_depth': max_depth_value,
#                     'n_estimators': n_estimators_value,
#                     'min_samples_leaf': min_samples_leaf_value
#                 }
# 
# print("Лучшие параметры:", best_params)
# print("Лучшая F1-метрика:", best_f1)

"""Лучшие параметры: {'max_depth': 9, 'n_estimators': 180, 'min_samples_leaf': 4}

Лучшая F1-метрика: 0.636663007683864
"""

model = RandomForestClassifier(random_state=12345, n_estimators=180, max_depth=9, min_samples_leaf=4, class_weight='balanced')
model.fit(features_train, target_train)
metrics = evaluate_model(model, features_valid, target_valid)
print(metrics)

"""После использования взвешивания классов для модели RandomForestClassifier, получены следующие результаты на валидационной выборке:

- Accuracy: 0.83
- Precision: 0.59
- Recall: 0.69
- F1 Score: 0.64
- ROC AUC: 0.85

Матрица ошибок выглядит следующим образом:

[1379,  203]

[ 128,  290]

Использование взвешивания классов привело к улучшению показателей Recall и F1-меры, что означает, что модель стала лучше обнаруживать положительные объекты и достигает лучшего компромисса между точностью и полнотой.
"""

penalty_options = ['l2']
solver_options = ['newton-cg', 'lbfgs', 'sag', 'saga']
C_values = [0.001, 0.01, 0.1, 1, 10, 100]

best_f1 = 0
best_params = {}

for penalty_value in penalty_options:
    for solver_value in solver_options:
        for C_value in C_values:
            model = LogisticRegression(
                random_state=12345,
                penalty=penalty_value,
                solver=solver_value,
                C=C_value,
                class_weight='balanced'
            )

            model.fit(features_train, target_train)

            predictions_valid = model.predict(features_valid)

            f1 = f1_score(target_valid, predictions_valid)

            if f1 > best_f1:
                best_f1 = f1
                best_params = {
                    'penalty': penalty_value,
                    'solver': solver_value,
                    'C': C_value
                }

print("Лучшие параметры:", best_params)
print("Лучшая F1-метрика:", best_f1)

model = LogisticRegression(random_state=12345, penalty='l2', solver='newton-cg', C=0.001, class_weight='balanced')
model.fit(features_train, target_train)
metrics = evaluate_model(model, features_valid, target_valid)
print(metrics)

"""После использования взвешивания классов для модели LogisticRegression, получены следующие результаты на валидационной выборке:

- Accuracy: 0.71
- Precision: 0.39
- Recall: 0.68
- F1 Score: 0.49
- ROC AUC: 0.76

Матрица ошибок выглядит следующим образом:

[1131,  451]

[ 135,  283]

Использование взвешивания классов позволило увеличить показатель Recall, что означает, что модель стала лучше обнаруживать положительные объекты. Однако, Precision снизилась, что может быть компромиссом для увеличения полноты.

Все показатели у модели RandomForestClassifier, такие как Accuracy, Precision, Recall, F1 Score и ROC AUC, также показали лучшие результаты по сравнению с моделью DecisionTreeClassifier и моделью LogisticRegression с взвешиванием классов. Модель RandomForestClassifier с взвешиванием классов оказалась наилучшей для данной задачи классификации, обеспечивая хороший баланс между точностью и полнотой.

Используем второй метод борьбы с дисбалансом - увеличение выборки.
"""

repeat_range = range(1, 10)
best_repeat, best_balance = find_optimal_repeat_for_balance(features_train, target_train, repeat_range)
print(f"Оптимальный repeat: {best_repeat}")

"""Оптимальным значением repeat для нашего случая будет 4"""

repeat = best_repeat

features_upsampled_train, target_upsampled_train = upsample(features_train, target_train, repeat)

count_class_0 = target_train.value_counts()[0]
count_class_1 = target_train.value_counts()[1]

count_upsampled_class_0 = target_upsampled_train.value_counts()[0]
count_upsampled_class_1 = target_upsampled_train.value_counts()[1]

print(f"Кольчество отрицательных классов до upsample: {count_class_0}")
print(f"Кольчество положительных классов до upsample: {count_class_1}")

print(f"Кольчество отрицательных классов после upsample: {count_upsampled_class_0}")
print(f"Кольчество положительных классов после upsample: {count_upsampled_class_1}")

plt.figure(figsize=(6, 4))
plt.bar(['Класс 0', 'Класс 1'], [count_class_0, count_class_1], label='До увеличения выборки')
plt.bar(['Класс 0', 'Класс 1'], [count_upsampled_class_0, count_upsampled_class_1], label='После увеличения выборки', alpha=0.7)
plt.xlabel('Класс')
plt.ylabel('Количество')
plt.legend()
plt.title('Распределение классов до и после увеличения выборки')
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# max_depth_range = range(1, 17)
# criterion_options = ['gini', 'entropy']
# min_samples_leaf_options = range(1, 21)
# 
# best_f1 = 0
# best_params = {}
# 
# for max_depth_value in tqdm(max_depth_range, desc="max_depth"):
#     for criterion_value in criterion_options:
#         for min_samples_leaf_value in min_samples_leaf_options:
#             model = DecisionTreeClassifier(
#                 random_state=12345,
#                 max_depth=max_depth_value,
#                 criterion=criterion_value,
#                 min_samples_leaf=min_samples_leaf_value
#             )
# 
#             model.fit(features_upsampled_train, target_upsampled_train)
# 
#             predictions_valid = model.predict(features_valid)
# 
#             f1 = f1_score(target_valid, predictions_valid)
# 
#             if f1 > best_f1:
#                 best_f1 = f1
#                 best_params = {
#                     'max_depth': max_depth_value,
#                     'criterion': criterion_value,
#                     'min_samples_leaf': min_samples_leaf_value
#                 }
# 
# print("Лучшие параметры:", best_params)
# print("Лучшая F1-метрика:", best_f1)

model = DecisionTreeClassifier(random_state=12345, max_depth=5, criterion='entropy', min_samples_leaf=19)
model.fit(features_upsampled_train, target_upsampled_train)
metrics = evaluate_model(model, features_valid, target_valid)
print(metrics)

"""После использования увеличения выборки для борьбы с дисбалансом классов, модель DecisionTreeClassifier показала следующие результаты на валидационной выборке:

- Accuracy: 0.81
- Precision: 0.54
- Recall: 0.68
- F1 Score: 0.60
- ROC AUC: 0.84

Матрица ошибок выглядит следующим образом:

[1340, 242]

[133, 285]

Сравнив эти результаты с показателями DecisionTreeClassifier, полученными после взвешивания классов, можно сделать следующие выводы:

- Accuracy и ROC AUC остались практически неизменными в обоих случаях и составили около 0.81 и 0.84 соответственно.

- Precision также осталась практически на том же уровне и составила около 0.54 (в случае увеличения выборки) и 0.55 (при взвешивании классов).

- Recall остался стабильным на уровне 0.68 как в случае увеличения выборки, так и в случае взвешивания классов.

- F1 Score также осталась неизменной и составила 0.60 в обоих случаях.

Оба метода, увеличение выборки и взвешивание классов, показали сходные результаты, но в данном случае предпочтительнее использовать увеличение выборки, так как она несколько увеличивает показатель Precision.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# max_depth_range = range(1, 17)
# n_estimators_range = list(range(10, 301, 10))
# min_samples_leaf_range = range(1, 21)
# 
# best_f1 = 0
# best_params = {}
# 
# for max_depth_value in max_depth_range:
#     for n_estimators_value in tqdm(n_estimators_range, desc=f"max_depth={max_depth_value}"):
#         for min_samples_leaf_value in min_samples_leaf_range:
#             model = RandomForestClassifier(
#                 random_state=12345,
#                 max_depth=max_depth_value,
#                 n_estimators=n_estimators_value,
#                 min_samples_leaf=min_samples_leaf_value
#             )
# 
#             model.fit(features_upsampled_train, target_upsampled_train)
# 
#             predictions_valid = model.predict(features_valid)
# 
#             f1 = f1_score(target_valid, predictions_valid)
# 
#             if f1 > best_f1:
#                 best_f1 = f1
#                 best_params = {
#                     'max_depth': max_depth_value,
#                     'n_estimators': n_estimators_value,
#                     'min_samples_leaf': min_samples_leaf_value
#                 }
# 
# print("Лучшие параметры:", best_params)
# print("Лучшая F1-метрика:", best_f1)

"""Лучшие параметры: {'max_depth': 15, 'n_estimators': 100, 'min_samples_leaf': 8}

Лучшая F1-метрика: 0.6372443487621098
"""

model = RandomForestClassifier(random_state=12345, n_estimators=100, max_depth=15, min_samples_leaf=8)
model.fit(features_upsampled_train, target_upsampled_train)
metrics = evaluate_model(model, features_valid, target_valid)
print(metrics)

"""После использования увеличения выборки для устранения дисбаланса классов в модели RandomForestClassifier, были получены следующие показатели на валидационной выборке:

- Accuracy: 0.82
- Precision: 0.56
- Recall: 0.69
- F1 Score: 0.62
- ROC AUC: 0.85

Матрица ошибок выглядит следующим образом:

[1353, 229]

[129, 289]

Сравнив эти результаты с показателями RandomForestClassifier, полученными после взвешивания классов, можно сделать следующие выводы:

- Accuracy осталась на примерно одинаковом уровне, составляя около 0.82 (при увеличении выборки) и 0.83 (при взвешивании классов).

- Precision осталась стабильной и составила около 0.56 в обоих случаях.

- Recall осталась также практически на том же уровне в обоих случаях, около 0.69 (при увеличении выборки) и 0.67 (при взвешивании классов).

- F1 Score осталась неизменной и составила около 0.62 в обоих случаях.

- ROC AUC осталась стабильной и составила 0.85 как при увеличении выборки, так и при взвешивании классов.

Оба метода, увеличение выборки и взвешивание классов, показали сходные результаты для модели RandomForestClassifier. Однако, в данном случае, предпочтительнее использовать увеличение выборки, так как оно показывает немного более высокий показатель Recall, что важно для задачи классификации.
"""

penalty_options = ['l2']
solver_options = ['newton-cg', 'lbfgs', 'sag', 'saga']
C_values = [0.001, 0.01, 0.1, 1, 10, 100]

best_f1 = 0
best_params = {}

for penalty_value in penalty_options:
    for solver_value in solver_options:
        for C_value in C_values:
            model = LogisticRegression(
                random_state=12345,
                penalty=penalty_value,
                solver=solver_value,
                C=C_value,
            )

            model.fit(features_upsampled_train, target_upsampled_train)

            predictions_valid = model.predict(features_valid)

            f1 = f1_score(target_valid, predictions_valid)

            if f1 > best_f1:
                best_f1 = f1
                best_params = {
                    'penalty': penalty_value,
                    'solver': solver_value,
                    'C': C_value
                }

print("Лучшие параметры:", best_params)
print("Лучшая F1-метрика:", best_f1)

model = LogisticRegression(random_state=12345, penalty='l2', solver='newton-cg', C=0.001)
model.fit(features_upsampled_train, target_upsampled_train)
metrics = evaluate_model(model, features_valid, target_valid)
print(metrics)

"""После использования увеличения выборки для устранения дисбаланса классов в модели LogisticRegression, были получены следующие показатели на валидационной выборке:

- Accuracy: 0.70
- Precision: 0.38
- Recall: 0.68
- F1 Score: 0.49
- ROC AUC: 0.76

Матрица ошибок выглядит следующим образом:

[1123, 459]

[134, 284]

Сравнив эти результаты с показателями LogisticRegression, полученными после взвешивания классов, можно сделать следующие выводы:

- Accuracy осталась на примерно одинаковом уровне, составляя около 0.70 (при увеличении выборки) и 0.70 (при взвешивании классов).

- Precision осталась стабильной и составила около 0.38 в обоих случаях.

- Recall осталась практически неизменной, около 0.68 (при увеличении выборки) и 0.67 (при взвешивании классов).

- F1 Score осталась неизменной и составила около 0.49 в обоих случаях.

- ROC AUC осталась стабильной и составила 0.76 как при увеличении выборки, так и при взвешивании классов.

Оба метода, увеличение выборки и взвешивание классов, показали сходные результаты для модели LogisticRegression. В данном случае, нет значительной разницы между двумя методами, и выбор может зависеть от особенностей задачи и предпочтений.

Используем третий метод борьбы с дисбалансом - уменьшение выборки.

Узнаем какой показатель fraction для функции downsample будет оптимальным.
"""

fraction_range = np.arange(0.1, 1.0, 0.1)
best_fraction, best_balance = find_optimal_fraction_for_balance(features_train, target_train, fraction_range)
print(f"Оптимальный fraction: {best_fraction}")

fraction = best_fraction

features_downsampled_train, target_downsampled_train = downsample(features_train, target_train, fraction)

count_class_0 = target_train.value_counts()[0]
count_class_1 = target_train.value_counts()[1]

count_downsampled_class_0 = target_downsampled_train.value_counts()[0]
count_downsampled_class_1 = target_downsampled_train.value_counts()[1]

print(f"Кольчество отрицательных классов до downsample: {count_class_0}")
print(f"Кольчество положительных классов до downsample: {count_class_1}")

print(f"Кольчество отрицательных классов после downsample: {count_downsampled_class_0}")
print(f"Кольчество положительных классов после downsample: {count_downsampled_class_1}")

plt.figure(figsize=(6, 4))
plt.bar(['Класс 0', 'Класс 1'], [count_class_0, count_class_1], label='До уменьшения выборки')
plt.bar(['Класс 0', 'Класс 1'], [count_downsampled_class_0, count_downsampled_class_1], label='После уменьшения выборки', alpha=0.7)
plt.xlabel('Класс')
plt.ylabel('Количество')
plt.legend()
plt.title('Распределение классов до и после уменьшения выборки')
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# max_depth_range = range(1, 17)
# criterion_options = ['gini', 'entropy']
# min_samples_leaf_options = range(1, 21)
# 
# best_f1 = 0
# best_params = {}
# 
# for max_depth_value in tqdm(max_depth_range, desc="max_depth"):
#     for criterion_value in criterion_options:
#         for min_samples_leaf_value in min_samples_leaf_options:
#             model = DecisionTreeClassifier(
#                 random_state=12345,
#                 max_depth=max_depth_value,
#                 criterion=criterion_value,
#                 min_samples_leaf=min_samples_leaf_value
#             )
# 
#             model.fit(features_downsampled_train, target_downsampled_train)
# 
#             predictions_valid = model.predict(features_valid)
# 
#             f1 = f1_score(target_valid, predictions_valid)
# 
#             if f1 > best_f1:
#                 best_f1 = f1
#                 best_params = {
#                     'max_depth': max_depth_value,
#                     'criterion': criterion_value,
#                     'min_samples_leaf': min_samples_leaf_value
#                 }
# 
# print("Лучшие параметры:", best_params)
# print("Лучшая F1-метрика:", best_f1)

model = DecisionTreeClassifier(random_state=12345, max_depth=6, criterion='entropy', min_samples_leaf=5)
model.fit(features_downsampled_train, target_downsampled_train)
metrics = evaluate_model(model, features_valid, target_valid)
print(metrics)

"""После использования уменьшения выборки для устранения дисбаланса классов в модели DecisionTreeClassifier, были получены следующие показатели на валидационной выборке:

- Accuracy: 0.76
- Precision: 0.46
- Recall: 0.79
- F1 Score: 0.58
- ROC AUC: 0.83


Матрица ошибок:

[1198, 384]

[ 88, 330]

Сравнение с результатами DecisionTreeClassifier после увеличения выборки:

Уменьшение выборки позволило достичь хорошего Recall, который составляет 0.79, что означает, что модель лучше способна обнаруживать положительные объекты. Однако, Precision снизился до 0.46, что может быть компромиссом для повышения полноты. Это также повлекло за собой небольшое снижение F1-меры до 0.58.

По сравнению с результатами после увеличения выборки, модель, обученная после уменьшения выборки, обладает высокой полнотой, но показывает немного худшие показатели в точности и F1-мере.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# max_depth_range = range(1, 17)
# n_estimators_range = list(range(10, 301, 10))
# min_samples_leaf_range = range(1, 21)
# 
# best_f1 = 0
# best_params = {}
# 
# for max_depth_value in max_depth_range:
#     for n_estimators_value in tqdm(n_estimators_range, desc=f"max_depth={max_depth_value}"):
#         for min_samples_leaf_value in min_samples_leaf_range:
#             model = RandomForestClassifier(
#                 random_state=12345,
#                 max_depth=max_depth_value,
#                 n_estimators=n_estimators_value,
#                 min_samples_leaf=min_samples_leaf_value
#             )
# 
#             model.fit(features_downsampled_train, target_downsampled_train)
# 
#             predictions_valid = model.predict(features_valid)
# 
#             f1 = f1_score(target_valid, predictions_valid)
# 
#             if f1 > best_f1:
#                 best_f1 = f1
#                 best_params = {
#                     'max_depth': max_depth_value,
#                     'n_estimators': n_estimators_value,
#                     'min_samples_leaf': min_samples_leaf_value
#                 }
# 
# print("Лучшие параметры:", best_params)
# print("Лучшая F1-метрика:", best_f1)

"""Лучшие параметры: {'max_depth': 6, 'n_estimators': 10, 'min_samples_leaf': 7}

Лучшая F1-метрика: 0.5734024179620035
"""

model = RandomForestClassifier(random_state=12345, n_estimators=10, max_depth=6, min_samples_leaf=7)
model.fit(features_downsampled_train, target_downsampled_train)
metrics = evaluate_model(model, features_valid, target_valid)
print(metrics)

"""После использования уменьшения выборки для устранения дисбаланса классов в модели RandomForestClassifier, были получены следующие показатели на валидационной выборке:

- Accuracy: 0.75
- Precision: 0.45
- Recall: 0.79
- F1 Score: 0.57
- ROC AUC: 0.84


Матрица ошибок:

[1174, 408]

[ 86, 332]

Сравнение с результатами RandomForestClassifier после увеличения выборки:

Уменьшение выборки позволило достичь хорошего Recall, который составляет 0.79, что означает, что модель лучше способна обнаруживать положительные объекты. Однако, Precision снизилась до 0.45, что может быть компромиссом для повышения полноты. Это также повлекло за собой снижение F1-меры до 0.57.

По сравнению с результатами после увеличения выборки, модель, обученная после уменьшения выборки, обладает высокой полнотой, но показывает немного худшие показатели в точности и F1-мере.
"""

penalty_options = ['l2']
solver_options = ['newton-cg', 'lbfgs', 'sag', 'saga']
C_values = [0.001, 0.01, 0.1, 1, 10, 100]

best_f1 = 0
best_params = {}

for penalty_value in penalty_options:
    for solver_value in solver_options:
        for C_value in C_values:
            model = LogisticRegression(
                random_state=12345,
                penalty=penalty_value,
                solver=solver_value,
                C=C_value,
            )

            model.fit(features_downsampled_train, target_downsampled_train)

            predictions_valid = model.predict(features_valid)

            f1 = f1_score(target_valid, predictions_valid)

            if f1 > best_f1:
                best_f1 = f1
                best_params = {
                    'penalty': penalty_value,
                    'solver': solver_value,
                    'C': C_value
                }

print("Лучшие параметры:", best_params)
print("Лучшая F1-метрика:", best_f1)

model = LogisticRegression(random_state=12345, penalty='l2', solver='newton-cg', C=0.01)
model.fit(features_train, target_train)
metrics = evaluate_model(model, features_valid, target_valid)
print(metrics)

"""После использования уменьшения выборки для устранения дисбаланса классов в модели LogisticRegression, были получены следующие показатели на валидационной выборке:

- Accuracy: 0.80
- Precision: 0.61
- Recall: 0.18
- F1 Score: 0.28
- ROC AUC: 0.76

Матрица ошибок:

[1533, 49]

[342, 76]

Сравнение с результатами LogisticRegression после увеличения выборки:

Уменьшение выборки привело к некоторому улучшению Precision, который составляет 0.61, но при этом Recall значительно снизился до 0.18. Это привело к ухудшению F1-меры, которая составила 0.28.

По сравнению с результатами после увеличения выборки, модель, обученная после уменьшения выборки, показывает более высокую точность, но значительно худшую полноту.

По сравнению с результатами после увеличения выборки, модели после уменьшения выборки демонстрируют высокий Recall, что означает, что они лучше способны обнаруживать положительные объекты. Однако, Precision снижается, что может быть компромиссом для повышения полноты. В целом, каждая из моделей имеет свои преимущества и недостатки.

Лучшей моделью может быть RandomForestClassifier, так как она демонстрирует хороший баланс между Precision и Recall, обеспечивая высокий F1 Score и ROC AUC.

## Тестирование модели
"""

features_train_full = pd.concat([features_train, features_valid])
target_train_full = pd.concat([target_train, target_valid])

repeat_range = range(1, 10)
best_repeat, best_balance = find_optimal_repeat_for_balance(features_train_full, target_train_full, repeat_range)
print(f"Оптимальный repeat: {best_repeat}")

repeat = best_repeat

features_upsampled_train_full, target_upsampled_train_full = upsample(features_train_full, target_train_full, repeat)

count_class_full_0 = target_train_full.value_counts()[0]
count_class_full_1 = target_train_full.value_counts()[1]

count_upsampled_class_full_0 = target_upsampled_train_full.value_counts()[0]
count_upsampled_class_full_1 = target_upsampled_train_full.value_counts()[1]

print(f"Кольчество отрицательных классов до upsample: {count_class_full_0}")
print(f"Кольчество положительных классов до upsample: {count_class_full_1}")

print(f"Кольчество отрицательных классов после upsample: {count_upsampled_class_full_0}")
print(f"Кольчество положительных классов после upsample: {count_upsampled_class_full_1}")

plt.figure(figsize=(6, 4))
plt.bar(['Класс 0', 'Класс 1'], [count_class_full_0, count_class_full_1], label='До увеличения выборки')
plt.bar(['Класс 0', 'Класс 1'], [count_upsampled_class_full_0, count_upsampled_class_full_1], label='После увеличения выборки', alpha=0.7)
plt.xlabel('Класс')
plt.ylabel('Количество')
plt.legend()
plt.title('Распределение классов до и после увеличения выборки')
plt.show()

model = RandomForestClassifier(random_state=12345, n_estimators=100, max_depth=15, min_samples_leaf=8)
model.fit(features_upsampled_train_full, target_upsampled_train_full)
metrics = evaluate_model(model, features_test, target_test)
print(metrics)

"""После дообучения модели RandomForestClassifier с использованием upsample и проверки ее на тестовой выборке получены следующие показатели:

- Accuracy: 0.82
- Precision: 0.57
- Recall: 0.66
- F1 Score: 0.61
- ROC AUC: 0.85

Матрица ошибок:

[1363, 214]

[ 142, 281]

Модель RandomForestClassifier показывает хорошие показатели Precision и Recall на тестовой выборке. Она способна обнаруживать положительные объекты с высокой точностью (57%) и уровнем полноты (66%). F1-мера, которая учитывает как точность, так и полноту, составляет 0.61, что также является хорошим показателем.

ROC AUC равный 0.85 свидетельствует о хорошей способности модели разделять классы. Таким образом, модель RandomForestClassifier, обученная с использованием upsample и проверенная на тестовой выборке, демонстрирует хорошие показатели обобщения и способна хорошо справляться с дисбалансом классов.

Целью данного проекта было построение модели для прогнозирования ухода клиентов из "Бета-Банка". Важной задачей было повышение значения F1-меры до минимума 0.59. Проект был разделен на несколько этапов, начиная с загрузки и предварительной обработки данных, затем исследования баланса классов, улучшения качества модели с учетом дисбаланса, и финального тестирования.

Исследованы три модели классификации с учетом дисбаланса классов: DecisionTreeClassifier, RandomForestClassifier и LogisticRegression. DecisionTreeClassifier и RandomForestClassifier показали хорошие показатели точности и полноты. LogisticRegression демонстрирует более низкие показатели. Лучшей моделью может быть RandomForestClassifier, так как она обеспечивает хороший баланс между точностью и полнотой.

Модели, обученные после уменьшения выборки, демонстрируют хороший Recall, что означает, что они лучше способны обнаруживать положительные объекты. Однако, Precision снижается, что может быть компромиссом для повышения полноты.

Модель RandomForestClassifier, обученная с использованием увеличения выборки и проверенная на тестовой выборке, демонстрирует хорошие показатели Precision, Recall и F1 Score. ROC AUC также высокий, что свидетельствует о хорошей способности модели разделять классы. Модель успешно справляется с дисбалансом классов.

Были достигнуты важные цели. При поставленной задаче добиться F1-меры равно 0.59, получилось достичь F1-меру 0.61 на тестовой выборке. Модель RandomForestClassifier, обученная с использованием увеличением выборки, демонстрирует хорошие показатели при прогнозировании ухода клиентов из "Бета-Банка".
"""

